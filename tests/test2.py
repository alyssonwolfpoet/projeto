# ConfiguraÃ§Ã£o e Uso do Sistema RAG

def main():
    # URLs ou caminhos de documentos para indexaÃ§Ã£o
    sources = [
        "https://lilianweng.github.io/posts/2023-06-23-agent/",
        "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/"
    ]

    # Inicializa o sistema RAG
    rag_system = RAGSystem(
        model_name="llama3",
        embedding_model="nomic-embed-text",
        chunk_size=500,
        chunk_overlap=50
    )

    # 1. Carrega documentos
    print("Carregando documentos...")
    documents = rag_system.load_documents(sources)

    # 2. Prepara o vetorstore
    print("Preparando vetorstore...")
    retriever = rag_system.prepare_vectorstore(documents)

    # 3. Consultas de exemplo
    queries = [
        "O que sÃ£o agentes de IA?",
        "Como funciona o prompt engineering?",
        "Quais sÃ£o as principais tÃ©cnicas de engenharia de prompt?"
    ]

    # 4. Realizando consultas com diferentes mÃ©todos
    print("\n--- Consultas BÃ¡sicas ---")
    for query in queries:
        print(f"\nPergunta: {query}")
        
        # Consulta bÃ¡sica
        response = rag_system.advanced_query(query)
        print("Resposta:", response[:500] + "..." if len(response) > 500 else response)

    # 5. DemonstraÃ§Ã£o de recuperaÃ§Ã£o multi-query
    print("\n--- Multi-Query Retrieval ---")
    complex_query = "Explique as estratÃ©gias avanÃ§adas de prompt engineering"
    multi_docs = rag_system.multi_query_retrieval(complex_query)
    print(f"Documentos recuperados: {len(multi_docs)}")

    # 6. AvaliaÃ§Ã£o de consulta
    print("\n--- AvaliaÃ§Ã£o de Consulta ---")
    evaluation = rag_system.evaluate_query(
        "Quais sÃ£o os desafios na criaÃ§Ã£o de agentes de IA?"
    )
    print("AvaliaÃ§Ã£o da Resposta:", evaluation)

    # 7. Adicionando documentos personalizados
    custom_docs = [
        Document(
            page_content="Agentes de IA sÃ£o sistemas computacionais que podem perceber seu ambiente e tomar aÃ§Ãµes de forma autÃ´noma.",
            metadata={"source": "custom_definition"}
        )
    ]
    rag_system.add_custom_documents(custom_docs)

    # 8. Consulta apÃ³s adicionar documentos personalizados
    print("\n--- Consulta ApÃ³s Adicionar Documentos Personalizados ---")
    custom_query = "Defina agentes de IA de forma simples"
    custom_response = rag_system.advanced_query(custom_query, return_sources=True)
    print("Resposta:", custom_response['answer'])
    print("\nFontes:")
    for source in custom_response['sources']:
        print("-", source['metadata'])

if _name_ == "_main_":
    main()


# pip install -U langchain langchain-core langchain-community langchain-ollama chromadb


# New chat
# New chat
# Crie uma estrutura de langchain mais atual v0.3 usando rag e pg ollama
# Done
# Research Plan & Sources
# Research the latest LangChain v0.3 RAG implementation

# langchain_ibm 0.1.9 â€” ğŸ¦œğŸ”— LangChain 0.2.7
# How to implement an integration package | ğŸ¦œï¸ğŸ”— LangChain
# langchain_robocorp 0.0.10.post1 â€” ğŸ¦œğŸ”— LangChain 0.2.17
# LangChain v0.3 | ğŸ¦œï¸ğŸ”— LangChain
# Docusaurus | ğŸ¦œï¸ğŸ”— LangChain
# Evaluate a RAG application | ğŸ¦œï¸ğŸ› ï¸ LangSmith
# See 3 more documents
# Investigate Ollama integration for local language models

# ChatOllama | ğŸ¦œï¸ğŸ”— LangChain
# Ollama | ğŸ¦œï¸ğŸ”— LangChain
# OllamaEmbeddings | ğŸ¦œï¸ğŸ”— LangChain
# OllamaLLM | ğŸ¦œï¸ğŸ”— LangChain
# Run models locally | ğŸ¦œï¸ğŸ”— LangChain
# OpenLLM | ğŸ¦œï¸ğŸ”— LangChain
# See 2 more documents
# Create a sample code structure combining RAG with Ollama

# OllamaLLM | ğŸ¦œï¸ğŸ”— LangChain
# ChatOllama | ğŸ¦œï¸ğŸ”— LangChain
# Self-RAG using local LLMs | ğŸ¦œğŸ•¸ï¸LangGraph
# Ollama | ğŸ¦œï¸ğŸ”— LangChain
# arXiv | ğŸ¦œï¸ğŸ”— LangChain
# arXiv | ğŸ¦œï¸ğŸ”— LangChain
# See 8 more documents
# Selected Context
# langchain_ibm 0.1.9 â€” ğŸ¦œğŸ”— LangChain 0.2.7
# langchain_ibm 0.1.9 â€” ğŸ¦œğŸ”— LangChain 0.2.7 LangChain Core Community Experimental Text splitters ai21 airbyte anthropic astradb aws azure-dynamic-sessions chroma cohere couchbase elasticsearch exa fireworks google-community google-g
# How to implement an integration package | ğŸ¦œï¸ğŸ”— LangChain
# - [Implementing LangChain components](#implementing-langchain-components)- [Properties](#properties) - [Run Methods](#run-methods) - [Implementation](#implementation) - [Attributes](#attributes) - [Methods](#methods) - [Implementation](#implemen
# langchain_robocorp 0.0.10.post1 â€” ğŸ¦œğŸ”— LangChain 0.2.17
# langchain_robocorp 0.0.10.post1 â€” ğŸ¦œğŸ”— LangChain 0.2.17 This is a legacy site. Please use the latest v0.2 and v0.3 API references instead. LangChain Core Community Experimental Text splitters ai21 airbyte anthropic astradb aws azure-dynam
# Answer
# Aqui estÃ¡ um exemplo de como criar uma estrutura de RAG (Retrieval-Augmented Generation) usando LangChain v0.3 com Ollama:
# InstalaÃ§Ã£o das DependÃªncias
# bash
# Copy
# pip install -U langchain langchain-core langchain-community langchain-ollama chromadb

# CÃ³digo Completo de ImplementaÃ§Ã£o
# python
# Copy


